# CASML - Generative AI Hackathon RAG System

Há»‡ thá»‘ng **Retrieval-Augmented Generation (RAG)** modular cho cuá»™c thi [CASML Generative AI Hackathon](https://www.kaggle.com/competitions/casml-generative-ai-hackathon) trÃªn Kaggle.

## ğŸ“‹ Má»¥c lá»¥c

- [Giá»›i thiá»‡u](#giá»›i-thiá»‡u)
- [Kiáº¿n trÃºc há»‡ thá»‘ng](#kiáº¿n-trÃºc-há»‡-thá»‘ng)
- [Cáº¥u trÃºc dá»± Ã¡n](#cáº¥u-trÃºc-dá»±-Ã¡n)
- [CÃ i Ä‘áº·t](#cÃ i-Ä‘áº·t)
- [Sá»­ dá»¥ng](#sá»­-dá»¥ng)
- [Cáº¥u hÃ¬nh](#cáº¥u-hÃ¬nh)
- [MÃ´-Ä‘un chi tiáº¿t](#mÃ´-Ä‘un-chi-tiáº¿t)
- [TÃ¹y chá»‰nh & má»Ÿ rá»™ng](#tÃ¹y-chá»‰nh--má»Ÿ-rá»™ng)

---

## ğŸ¯ Giá»›i thiá»‡u

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng má»™t há»‡ thá»‘ng há»iâ€“Ä‘Ã¡p (Q&A) sá»­ dá»¥ng **RAG Pipeline** Ä‘á»ƒ:
1. **Truy xuáº¥t** cÃ¡c Ä‘oáº¡n vÄƒn liÃªn quan tá»« corpus (sÃ¡ch/tÃ i liá»‡u)
2. **Sinh cÃ¢u tráº£ lá»i** chÃ­nh xÃ¡c dá»±a trÃªn ngá»¯ cáº£nh Ä‘Æ°á»£c truy xuáº¥t báº±ng LLM

### Äáº·c Ä‘iá»ƒm chÃ­nh:
- âœ… **Modular**: Dá»… dÃ ng thay Ä‘á»•i embedding model, retriever, hoáº·c LLM
- âœ… **Reproducible**: Seed cá»‘ Ä‘á»‹nh, cáº¥u hÃ¬nh rÃµ rÃ ng
- âœ… **Flexible**: Há»— trá»£ nhiá»u chiáº¿n lÆ°á»£c retrieval (dense, sparse, hybrid)
- âœ… **Optimized**: Thiáº¿t káº¿ cho GPU háº¡n cháº¿, há»— trá»£ quantization
- âœ… **Kaggle-ready**: Script tá»± Ä‘á»™ng táº¡o submission file

---

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         RAG PIPELINE                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  1. DATA INGESTION LAYER                             â”‚
    â”‚     - Load corpus (books/documents)                  â”‚
    â”‚     - Parse & clean text                             â”‚
    â”‚     - Load Q&A dataset                               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  2. INDEXING LAYER                                   â”‚
    â”‚     - Text chunking (semantic/fixed-size)            â”‚
    â”‚     - Embedding generation (sentence-transformers)   â”‚
    â”‚     - Index building (FAISS/BM25/Hybrid)             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  3. RETRIEVAL LAYER                                  â”‚
    â”‚     - Query embedding                                â”‚
    â”‚     - Top-K retrieval (dense/sparse/hybrid)          â”‚
    â”‚     - Re-ranking (optional: cross-encoder)           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  4. GENERATION LAYER                                 â”‚
    â”‚     - Context assembly (retrieved chunks)            â”‚
    â”‚     - Prompt engineering                             â”‚
    â”‚     - LLM inference (HuggingFace/OpenAI/local)       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  5. EVALUATION & SUBMISSION LAYER                    â”‚
    â”‚     - Metric calculation (BLEU/ROUGE/Similarity)     â”‚
    â”‚     - Generate submission CSV                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
CASML-Generative-AI-Hackathon/
â”‚
â”œâ”€â”€ data/                          # Dá»¯ liá»‡u
â”‚   â”œâ”€â”€ raw/                       # Corpus & Q&A gá»‘c tá»« Kaggle
â”‚   â”œâ”€â”€ processed/                 # Chunks Ä‘Ã£ xá»­ lÃ½
â”‚   â”œâ”€â”€ embeddings/                # Vector embeddings
â”‚   â”œâ”€â”€ indexes/                   # FAISS/BM25 indexes
â”‚   â””â”€â”€ submissions/               # Submission files cho Kaggle
â”‚
â”œâ”€â”€ src/                           # Source code chÃ­nh
â”‚   â”œâ”€â”€ config/                    # Quáº£n lÃ½ cáº¥u hÃ¬nh
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ config_manager.py      # Load config.yaml & .env
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/                 # Load & preprocess dá»¯ liá»‡u
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_loader.py         # CorpusLoader, QADataLoader
â”‚   â”‚
â”‚   â”œâ”€â”€ indexing/                  # Chunking & embedding
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ indexer.py             # TextChunker, EmbeddingGenerator, IndexBuilder
â”‚   â”‚
â”‚   â”œâ”€â”€ retrieval/                 # Truy xuáº¥t documents
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ retriever.py           # Dense/Sparse/Hybrid retrieval + Re-ranking
â”‚   â”‚
â”‚   â”œâ”€â”€ generation/                # LLM inference
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ generator.py           # LLMGenerator, RAGPipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/                # Metrics & submission
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ evaluator.py           # Evaluator, SubmissionGenerator
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                     # Helper functions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ helpers.py             # Logging, seeding, timing
â”‚   â”‚
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ scripts/                       # Executable scripts
â”‚   â”œâ”€â”€ download_data.py           # Download Kaggle data
â”‚   â”œâ”€â”€ build_index.py             # Build embeddings & indexes
â”‚   â”œâ”€â”€ evaluate.py                # Evaluate on training set
â”‚   â”œâ”€â”€ generate_predictions.py    # Generate test predictions
â”‚   â””â”€â”€ run_pipeline.py            # Run end-to-end pipeline
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter notebooks
â”‚   â””â”€â”€ (EDA, experiments, visualization)
â”‚
â”œâ”€â”€ tests/                         # Unit tests
â”‚   â””â”€â”€ (pytest tests)
â”‚
â”œâ”€â”€ config.yaml                    # Cáº¥u hÃ¬nh chÃ­nh
â”œâ”€â”€ .env.example                   # Template cho biáº¿n mÃ´i trÆ°á»ng
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                      # File nÃ y
```

---

## ğŸš€ CÃ i Ä‘áº·t

### 1. Clone repository
```bash
git clone https://github.com/your-username/CASML-Generative-AI-Hackathon.git
cd CASML-Generative-AI-Hackathon
```

### 2. Táº¡o virtual environment
```powershell
# Windows PowerShell
python -m venv venv
.\venv\Scripts\Activate.ps1

# Linux/Mac
python -m venv venv
source venv/bin/activate
```

### 3. CÃ i Ä‘áº·t dependencies
```bash
pip install -r requirements.txt
```

**LÆ°u Ã½**: 
- Náº¿u cÃ³ GPU CUDA, dÃ¹ng `tensorflow-gpu` vÃ  `faiss-gpu`:
  ```bash
  pip install tensorflow-gpu==2.15.0
  pip install faiss-gpu
  ```
- Kiá»ƒm tra CUDA vÃ  cuDNN tÆ°Æ¡ng thÃ­ch: https://www.tensorflow.org/install/source#gpu

### 4. Cáº¥u hÃ¬nh API keys (tÃ¹y chá»n)
```bash
cp .env.example .env
# Chá»‰nh sá»­a .env vÃ  thÃªm API keys (náº¿u dÃ¹ng OpenAI/Anthropic/Kaggle)
```

---

## ğŸ’» Sá»­ dá»¥ng

### Pipeline hoÃ n chá»‰nh (Recommended)

Cháº¡y toÃ n bá»™ pipeline tá»« data Ä‘áº¿n submission:

```bash
python scripts/run_pipeline.py
```

### Tá»«ng bÆ°á»›c riÃªng láº»

#### BÆ°á»›c 1: Download dá»¯ liá»‡u tá»« Kaggle
```bash
python scripts/download_data.py
```
*YÃªu cáº§u: KAGGLE_USERNAME vÃ  KAGGLE_KEY trong .env*

#### BÆ°á»›c 2: Build search index
```bash
python scripts/build_index.py
```
Táº¡o chunks, embeddings, vÃ  FAISS/BM25 indexes.

#### BÆ°á»›c 3: Evaluate trÃªn training set
```bash
python scripts/evaluate.py
```
ÄÃ¡nh giÃ¡ model vá»›i BLEU, ROUGE, BERTScore trÃªn táº­p train.

#### BÆ°á»›c 4: Generate predictions cho test set
```bash
python scripts/generate_predictions.py
```
Táº¡o file submission CSV trong `data/submissions/`.

---

## âš™ï¸ Cáº¥u hÃ¬nh

Táº¥t cáº£ cáº¥u hÃ¬nh Ä‘Æ°á»£c quáº£n lÃ½ trong **`config.yaml`**.

### CÃ¡c pháº§n chÃ­nh:

#### 1. **Indexing**
```yaml
indexing:
  chunking:
    strategy: "semantic"  # fixed, semantic, sentence, paragraph
    chunk_size: 512
    chunk_overlap: 50
  
  embedding:
    model_name: "sentence-transformers/all-MiniLM-L6-v2"
    # Hoáº·c dÃ¹ng fine-tuned model:
    # model_name: "your-username/your-finetuned-model"
    device: "cuda"
    batch_size: 32
  
  index:
    type: "hybrid"  # faiss, bm25, hybrid
```

#### 2. **Retrieval**
```yaml
retrieval:
  strategy: "hybrid"  # dense, sparse, hybrid
  top_k: 5
  dense_weight: 0.6
  sparse_weight: 0.4
  
  use_reranker: true
  reranker_model: "cross-encoder/ms-marco-MiniLM-L-6-v2"
  rerank_top_k: 3
```

#### 3. **Generation**
```yaml
generation:
  model:
    provider: "huggingface"
    model_name: "google/flan-t5-base"
    # Hoáº·c: "meta-llama/Llama-2-7b-chat-hf"
    # Hoáº·c: "your-username/your-finetuned-llm"
    device: "cuda"
    load_in_8bit: false  # Quantization Ä‘á»ƒ tiáº¿t kiá»‡m VRAM
  
  inference:
    max_new_tokens: 256
    temperature: 0.3
    top_p: 0.9
  
  prompt:
    template: |
      Answer the question based on the context below.
      
      Context: {context}
      Question: {question}
      Answer:
```

#### 4. **Evaluation**
```yaml
evaluation:
  metrics:
    - "bleu"
    - "rouge"
    - "bertscore"
```

---

## ğŸ§© MÃ´-Ä‘un chi tiáº¿t

### 1. **Config Module** (`src/config/`)
- **Vai trÃ²**: Load cáº¥u hÃ¬nh tá»« `config.yaml` vÃ  `.env`
- **Sá»­ dá»¥ng**:
  ```python
  from src.config import get_config
  config = get_config()
  embedding_model = config.get('indexing.embedding.model_name')
  ```

### 2. **Ingestion Module** (`src/ingestion/`)
- **Vai trÃ²**: Load corpus vÃ  Q&A dataset, preprocessing text
- **Classes**:
  - `CorpusLoader`: Load vÃ  clean corpus
  - `QADataLoader`: Load train/test Q&A data
- **Flow**: Raw data â†’ Cleaned text

### 3. **Indexing Module** (`src/indexing/`)
- **Vai trÃ²**: Chunk text, táº¡o embeddings, build search indexes
- **Classes**:
  - `TextChunker`: Chia corpus thÃ nh chunks (fixed/semantic/sentence/paragraph)
  - `EmbeddingGenerator`: Táº¡o embeddings vá»›i sentence-transformers
  - `IndexBuilder`: Build FAISS (dense), BM25 (sparse), hoáº·c hybrid index
- **Flow**: Text â†’ Chunks â†’ Embeddings â†’ Index

### 4. **Retrieval Module** (`src/retrieval/`)
- **Vai trÃ²**: Truy xuáº¥t top-K documents liÃªn quan cho query
- **Class**: `Retriever`
  - Dense retrieval: FAISS similarity search
  - Sparse retrieval: BM25 keyword matching
  - Hybrid: Káº¿t há»£p dense + sparse vá»›i weighted fusion
  - Re-ranking: Cross-encoder Ä‘á»ƒ cáº£i thiá»‡n ranking
- **Flow**: Query â†’ Embeddings â†’ Search â†’ Re-rank â†’ Top-K chunks

### 5. **Generation Module** (`src/generation/`)
- **Vai trÃ²**: Sinh cÃ¢u tráº£ lá»i tá»« LLM
- **Classes**:
  - `LLMGenerator`: Wrapper cho HuggingFace models (T5, Llama, GPT, v.v.)
  - `RAGPipeline`: Káº¿t há»£p retrieval + generation
- **Flow**: Query â†’ Retrieve contexts â†’ Build prompt â†’ LLM inference â†’ Answer

### 6. **Evaluation Module** (`src/evaluation/`)
- **Vai trÃ²**: ÄÃ¡nh giÃ¡ predictions vÃ  táº¡o submission file
- **Classes**:
  - `Evaluator`: TÃ­nh BLEU, ROUGE, BERTScore, Exact Match
  - `SubmissionGenerator`: Táº¡o CSV submission cho Kaggle
- **Flow**: Predictions + References â†’ Metrics / Submission CSV

### 7. **Utils Module** (`src/utils/`)
- **Vai trÃ²**: Helper functions
- **Functions**:
  - `setup_logging()`: Cáº¥u hÃ¬nh logging
  - `set_seed()`: Set random seed cho reproducibility
  - `get_device()`: Auto-detect CUDA/MPS/CPU
  - `save_results()` / `load_results()`: Save/load JSON results

---

## ğŸ› ï¸ TÃ¹y chá»‰nh & má»Ÿ rá»™ng

### 1. Sá»­ dá»¥ng fine-tuned embedding model tá»« HuggingFace

Chá»‰nh sá»­a `config.yaml`:
```yaml
indexing:
  embedding:
    model_name: "your-username/your-finetuned-embedding-model"
    backend: "tensorflow"
```

### 2. Sá»­ dá»¥ng fine-tuned LLM

Chá»‰nh sá»­a `config.yaml`:
```yaml
generation:
  model:
    model_name: "your-username/your-finetuned-llm"
    backend: "tensorflow"
    use_mixed_precision: true  # Náº¿u GPU nhá»
```

### 3. Thay Ä‘á»•i chunking strategy

```yaml
indexing:
  chunking:
    strategy: "sentence"  # Thá»­ sentence-based chunking
```

### 4. Äiá»u chá»‰nh retrieval strategy

```yaml
retrieval:
  strategy: "dense"  # Chá»‰ dÃ¹ng dense retrieval
  top_k: 10          # TÄƒng sá»‘ chunks retrieve
```

### 5. Custom prompt template

Chá»‰nh sá»­a trong `config.yaml`:
```yaml
generation:
  prompt:
    template: |
      You are a helpful assistant. Answer concisely.
      
      Context:
      {context}
      
      Question: {question}
      
      Answer:
```

### 6. ThÃªm metrics má»›i

Chá»‰nh sá»­a `src/evaluation/evaluator.py` vÃ  implement metric tÃ¹y chá»‰nh trong class `Evaluator`.

---

## ğŸ§ª Testing

Cháº¡y unit tests:
```bash
pytest tests/
```

---

## ğŸ“Š Experiment Tracking (Optional)

### Sá»­ dá»¥ng Weights & Biases

1. Cáº¥u hÃ¬nh trong `config.yaml`:
```yaml
logging:
  use_wandb: true
  wandb_project: "casml-rag-hackathon"
```

2. Set API key trong `.env`:
```
WANDB_API_KEY=your_wandb_key
```

3. Log metrics tá»± Ä‘á»™ng khi cháº¡y scripts.

---

## ğŸ› ï¸ Troubleshooting

### GPU Out of Memory
- Giáº£m `batch_size` trong config
- Báº­t mixed precision: `use_mixed_precision: true` trong generation config
- Äáº·t `gpu_memory_limit` trong resources config (MB)
- Giáº£m `chunk_size` vÃ  `top_k`

### TensorFlow GPU khÃ´ng nháº­n
- Kiá»ƒm tra CUDA vÃ  cuDNN Ä‘Ã£ cÃ i Ä‘Ãºng phiÃªn báº£n
- Cháº¡y: `python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"`
- Báº­t `gpu_memory_growth: true` trong config

### FAISS Import Error
- CÃ i `faiss-gpu` náº¿u cÃ³ CUDA:
  ```bash
  pip uninstall faiss-cpu
  pip install faiss-gpu
  ```

### Kaggle API Error
- Äáº£m báº£o Ä‘Ã£ accept competition rules trÃªn Kaggle
- Kiá»ƒm tra `KAGGLE_USERNAME` vÃ  `KAGGLE_KEY` trong `.env`

---

## ğŸ“š TÃ i liá»‡u tham kháº£o

- **TensorFlow**: https://www.tensorflow.org/guide
- **HuggingFace Transformers**: https://huggingface.co/docs/transformers
- **Sentence Transformers**: https://www.sbert.net/
- **FAISS**: https://github.com/facebookresearch/faiss
- **LangChain**: https://python.langchain.com/
- **RAG Papers**: [RAG (Lewis et al., 2020)](https://arxiv.org/abs/2005.11401)

---

## ğŸ“„ License

MIT License

---

## ğŸ‘¥ Contributors

CASML Team - INSA Lyon

---

## ğŸ™ Acknowledgments

Cuá»™c thi Ä‘Æ°á»£c tá»• chá»©c bá»Ÿi CASML trÃªn ná»n táº£ng Kaggle.

